# Set

- [Set](#set)
  - [정의](#정의)
  - [Java 기준으로 주요 구현체와 시간 복잡도](#java-기준으로-주요-구현체와-시간-복잡도)
  - [내부 동작원리](#내부-동작원리)
    - [HashSet](#hashset)
    - [TreeSet](#treeset)
  - [알고리즘 테스트에서 어떻게 써먹을까요?](#알고리즘-테스트에서-어떻게-써먹을까요)
    - [1. 중복 제거](#1-중복-제거)
    - [2. 멤버십 테스트](#2-멤버십-테스트)
    - [3. 집합 연산](#3-집합-연산)
    - [4. 투 포인터, 투 셋](#4-투-포인터-투-셋)
    - [5. 순서 보장이 필요할 때](#5-순서-보장이-필요할-때)
  - [주의사항](#주의사항)

## 정의

- 중복 된 원소를 허용하지 않고 순서가 보장되지 않는 컬렉션입니다.
- Java 에서는 java.util.Set<E> 로 사용할 수 있죠.

## Java 기준으로 주요 구현체와 시간 복잡도

| 구현체           | 특징                            | 탐색/삽입/삭제 평균 |  탐색/삽입/삭제 최악 |  메모리 |            정렬 여부            |
| :------------ | :---------------------------- | :---------: | :----------: | :--: | :-------------------------: |
| HashSet       | 해시 기반, 내부적으로 배열+버킷(체이닝)       |     O(1)    | O(n)※해시 충돌 시 |  높음  |             불가능             |
| LinkedHashSet | HashSet + 이중 연결 리스트(삽입 순서 유지) |     O(1)    |     O(n)     | 더 높음 |             불가능             |
| TreeSet       | 레드–블랙 트리(균형 이진 탐색 트리)         |   O(log n)  |   O(log n)   |  중간  | 가능(`first()`, `subSet()` 등) |

## 내부 동작원리

### HashSet

- `hashCode()` 로 해시값을 계산 후 버킷 인덱스를 결정합니다.
- 동일 버킷인 경우 연결 리스트 (Java 8+) 에서는 트리로 관리합니다.
- 부하율 (load factor, 기본 0.75) 초과 시 배열 크기(버킷 수) 를 두 배로 확장시킵니다.

### TreeSet

- `Comparable` 또는 `Comparator` 로 비교합니다.
- 삽입, 삭제 시 트리 균형 (Red, Black) 을 유지합니다.

## 알고리즘 테스트에서 어떻게 써먹을까요?

### 1. 중복 제거

```java
int[] arr = {1,2,2,3,3,3};
Set<Integer> s = new HashSet<>();
for(int x: arr) s.add(x);
// s = {1,2,3}
```

### 2. 멤버십 테스트

- `contains` 빈도 계산, 투 포인터, 슬라이딩 윈도우에서 특정 값 존재 여부 조회

### 3. 집합 연산

- 교집합: retainAll()
- 합집합: addAll()
- 차집합: removeAll()

### 4. 투 포인터, 투 셋

- 서로 다른 두 수의 합 찾기

  ```java
  boolean twoSum(int[] nums, int target) {
      Set<Integer> seen = new HashSet<>();
      for(int x: nums) {
        if(seen.contains(target - x)) return true;
        seen.add(x);
      }
      return false;
  }
  ```

### 5. 순서 보장이 필요할 때

- 삽입 순서 유지 → LinkedHashSet
- 정렬된 결과 → TreeSet

## 주의사항

- 해시 충돌: equals()와 hashCode()를 올바르게 오버라이드해야 예상 성능 보장
- 메모리 트레이드오프: 해시 테이블은 빈 버킷을 위한 배열 공간을 확보하기 때문에 메모리 사용량이 큼
- 최악 복잡도: 해시 충돌 공격이나 매우 불균형한 입력 시 O(n)으로 성능 저하 가능
- 스레드 안정성: 멀티스레드 환경에서 동시 수정 시 ConcurrentHashMap.newKeySet() 등을 사용
